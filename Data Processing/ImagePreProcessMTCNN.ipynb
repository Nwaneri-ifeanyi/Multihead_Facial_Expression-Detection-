{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680bc453-d2e6-4bb8-b71e-5f9570d62481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bab2c1-5c7c-4d4f-bffb-624614904ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3b5b60-de2d-42ff-9fd1-c56f9495f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processing complete!\n",
      "158 images could not be recognized. See 'unrecognized_images.csv' for details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mtcnn = MTCNN(keep_all=False, device=device)\n",
    "\n",
    "# Directories\n",
    "IMG_AFFECT_DATA_DIR = \"./AffectNetUnzip/\"\n",
    "output_dir = \"./processed_data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Subdirectories for saving processed files\n",
    "aligned_images_dir = os.path.join(output_dir, \"aligned_images/\")\n",
    "landmarked_images_dir = os.path.join(output_dir, \"landmarked_images/\")\n",
    "tensor_dir = os.path.join(output_dir, \"tensors/\")\n",
    "metadata_file = os.path.join(output_dir, \"metadata.csv\")\n",
    "\n",
    "os.makedirs(aligned_images_dir, exist_ok=True)\n",
    "os.makedirs(landmarked_images_dir, exist_ok=True)\n",
    "os.makedirs(tensor_dir, exist_ok=True)\n",
    "\n",
    "# Splits and classes\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "\n",
    "# Metadata storage\n",
    "metadata = []\n",
    "\n",
    "def align_face(image):\n",
    "    \"\"\"Align face using MTCNN landmarks.\"\"\"\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert to PIL format\n",
    "    boxes, probs, landmarks = mtcnn.detect(image_pil, landmarks=True)\n",
    "    if landmarks is not None:\n",
    "        # Extract eye coordinates\n",
    "        left_eye = landmarks[0][0]\n",
    "        right_eye = landmarks[0][1]\n",
    "        dx = right_eye[0] - left_eye[0]\n",
    "        dy = right_eye[1] - left_eye[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Rotate image\n",
    "        center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        aligned_image = cv2.warpAffine(image, rot_mat, (image.shape[1], image.shape[0]))\n",
    "        return aligned_image, landmarks[0]\n",
    "    return image, None\n",
    "\n",
    "# Additional list to track unrecognized images\n",
    "unrecognized_images = []\n",
    "\n",
    "# Process images\n",
    "for split in splits:\n",
    "    split_dir = os.path.join(IMG_AFFECT_DATA_DIR, split)\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(split_dir, cls)\n",
    "        if os.path.isdir(class_dir):\n",
    "            images = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
    "            for img_path in images:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Attempt to align face\n",
    "                aligned_img, landmarks = align_face(img)\n",
    "                \n",
    "                if aligned_img is None or landmarks is None:\n",
    "                    # Log unrecognized images\n",
    "                    unrecognized_images.append({\n",
    "                        \"split\": split,\n",
    "                        \"class\": cls,\n",
    "                        \"path\": img_path\n",
    "                    })\n",
    "                    continue  # Skip to the next image\n",
    "                \n",
    "                # Save aligned image\n",
    "                aligned_save_path = os.path.join(aligned_images_dir, f\"{split}_{cls}_{os.path.basename(img_path)}\")\n",
    "                Image.fromarray(cv2.cvtColor(aligned_img, cv2.COLOR_BGR2RGB)).save(aligned_save_path)\n",
    "                \n",
    "                # Save image with landmarks\n",
    "                if landmarks is not None:\n",
    "                    for (x, y) in landmarks:\n",
    "                        cv2.circle(aligned_img, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "                    landmarked_save_path = os.path.join(landmarked_images_dir, f\"{split}_{cls}_landmarks_{os.path.basename(img_path)}\")\n",
    "                    Image.fromarray(cv2.cvtColor(aligned_img, cv2.COLOR_BGR2RGB)).save(landmarked_save_path)\n",
    "                \n",
    "                # Save tensor\n",
    "                tensor_save_path = os.path.join(tensor_dir, f\"{split}_{cls}_{os.path.splitext(os.path.basename(img_path))[0]}.pt\")\n",
    "                aligned_tensor = torch.from_numpy(cv2.cvtColor(aligned_img, cv2.COLOR_BGR2RGB)).permute(2, 0, 1)\n",
    "                torch.save(aligned_tensor, tensor_save_path)\n",
    "                \n",
    "                # Store metadata\n",
    "                metadata.append({\n",
    "                    \"split\": split,\n",
    "                    \"class\": cls,\n",
    "                    \"original_path\": img_path,\n",
    "                    \"aligned_path\": aligned_save_path,\n",
    "                    \"landmarked_path\": landmarked_save_path if landmarks is not None else None,\n",
    "                    \"tensor_path\": tensor_save_path,\n",
    "                    \"landmarks\": landmarks.tolist(),\n",
    "                    \"is_recognized\": True\n",
    "                })\n",
    "\n",
    "# Save metadata to CSV\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df.to_csv(metadata_file, index=False)\n",
    "\n",
    "# Save unrecognized images to a separate CSV\n",
    "if unrecognized_images:\n",
    "    unrecognized_df = pd.DataFrame(unrecognized_images)\n",
    "    unrecognized_df.to_csv(os.path.join(output_dir, \"unrecognized_images.csv\"), index=False)\n",
    "\n",
    "print(\"All processing complete!\")\n",
    "if unrecognized_images:\n",
    "    print(f\"{len(unrecognized_images)} images could not be recognized. See 'unrecognized_images.csv' for details.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
